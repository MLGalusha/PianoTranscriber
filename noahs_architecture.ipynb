{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import numpy as np\n",
    "from audio_midi_pipeline import process_files\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, GRU, Dense, Flatten, Reshape\n",
    "\n",
    "# Additional import for setting up the input shape\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_files('songs/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[:, 513:]\n",
    "inputs = df.iloc[:, :513]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.318600</td>\n",
       "      <td>1.141339</td>\n",
       "      <td>0.730707</td>\n",
       "      <td>0.318147</td>\n",
       "      <td>0.045598</td>\n",
       "      <td>0.054625</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.074866</td>\n",
       "      <td>0.109161</td>\n",
       "      <td>0.082477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.872762</td>\n",
       "      <td>1.272308</td>\n",
       "      <td>0.297969</td>\n",
       "      <td>0.446068</td>\n",
       "      <td>0.481981</td>\n",
       "      <td>0.180617</td>\n",
       "      <td>0.077836</td>\n",
       "      <td>0.179556</td>\n",
       "      <td>0.091405</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.754176</td>\n",
       "      <td>1.561906</td>\n",
       "      <td>0.646229</td>\n",
       "      <td>0.561347</td>\n",
       "      <td>0.438459</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.172674</td>\n",
       "      <td>0.219635</td>\n",
       "      <td>0.108360</td>\n",
       "      <td>0.037893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.651110</td>\n",
       "      <td>1.539175</td>\n",
       "      <td>1.214260</td>\n",
       "      <td>0.623981</td>\n",
       "      <td>0.100822</td>\n",
       "      <td>0.081278</td>\n",
       "      <td>0.084314</td>\n",
       "      <td>0.104347</td>\n",
       "      <td>0.038962</td>\n",
       "      <td>0.063621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965757</td>\n",
       "      <td>1.067958</td>\n",
       "      <td>0.903161</td>\n",
       "      <td>0.450302</td>\n",
       "      <td>0.140402</td>\n",
       "      <td>0.093487</td>\n",
       "      <td>0.118966</td>\n",
       "      <td>0.146267</td>\n",
       "      <td>0.126340</td>\n",
       "      <td>0.065956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.318600  1.141339  0.730707  0.318147  0.045598  0.054625  0.015487   \n",
       "1  0.872762  1.272308  0.297969  0.446068  0.481981  0.180617  0.077836   \n",
       "2  1.754176  1.561906  0.646229  0.561347  0.438459  0.062829  0.172674   \n",
       "3  1.651110  1.539175  1.214260  0.623981  0.100822  0.081278  0.084314   \n",
       "4  0.965757  1.067958  0.903161  0.450302  0.140402  0.093487  0.118966   \n",
       "\n",
       "        7         8         9    ...       503       504       505       506  \\\n",
       "0  0.074866  0.109161  0.082477  ...  0.000508  0.000256  0.000290  0.000401   \n",
       "1  0.179556  0.091405  0.047237  ...  0.000388  0.000059  0.000299  0.000291   \n",
       "2  0.219635  0.108360  0.037893  ...  0.000037  0.000520  0.000866  0.000728   \n",
       "3  0.104347  0.038962  0.063621  ...  0.000743  0.000816  0.000818  0.000555   \n",
       "4  0.146267  0.126340  0.065956  ...  0.000835  0.000364  0.000947  0.001188   \n",
       "\n",
       "        507       508       509       510       511       512  \n",
       "0  0.000345  0.000168  0.000488  0.000713  0.000727  0.000710  \n",
       "1  0.000599  0.000536  0.000238  0.000974  0.001147  0.001166  \n",
       "2  0.000402  0.000291  0.000320  0.000437  0.000553  0.000231  \n",
       "3  0.000726  0.000914  0.000230  0.000354  0.000864  0.000859  \n",
       "4  0.000581  0.000839  0.000088  0.001167  0.001447  0.000313  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_21</th>\n",
       "      <th>pitch_22</th>\n",
       "      <th>pitch_23</th>\n",
       "      <th>pitch_24</th>\n",
       "      <th>pitch_25</th>\n",
       "      <th>pitch_26</th>\n",
       "      <th>pitch_27</th>\n",
       "      <th>pitch_28</th>\n",
       "      <th>pitch_29</th>\n",
       "      <th>pitch_30</th>\n",
       "      <th>...</th>\n",
       "      <th>pitch_99</th>\n",
       "      <th>pitch_100</th>\n",
       "      <th>pitch_101</th>\n",
       "      <th>pitch_102</th>\n",
       "      <th>pitch_103</th>\n",
       "      <th>pitch_104</th>\n",
       "      <th>pitch_105</th>\n",
       "      <th>pitch_106</th>\n",
       "      <th>pitch_107</th>\n",
       "      <th>pitch_108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pitch_21  pitch_22  pitch_23  pitch_24  pitch_25  pitch_26  pitch_27  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   pitch_28  pitch_29  pitch_30  ...  pitch_99  pitch_100  pitch_101  \\\n",
       "0         0         0         0  ...         0          0          0   \n",
       "1         0         0         0  ...         0          0          0   \n",
       "2         0         0         0  ...         0          0          0   \n",
       "3         0         0         0  ...         0          0          0   \n",
       "4         0         0         0  ...         0          0          0   \n",
       "\n",
       "   pitch_102  pitch_103  pitch_104  pitch_105  pitch_106  pitch_107  pitch_108  \n",
       "0          0          0          0          0          0          0          0  \n",
       "1          0          0          0          0          0          0          0  \n",
       "2          0          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(input.head(5))\n",
    "display(labels.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=np.random.rand(10, 1)\n",
    "# display(x)\n",
    "\n",
    "# LSTM(5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=np.random.rand(1, 5, 513, 1)\n",
    "# x_2=Conv2D(10, kernel_size=(3,3), activation='relu', input_shape=(5, 513, 1))(x)\n",
    "# x_3=MaxPooling2D(pool_size=(3, 3))(x_2)\n",
    "# print(f'x_3 shape: {x_3.shape}')\n",
    "# x_4=Flatten()(x_3)\n",
    "# # x_4=Reshape(target_shape=())(x_3)\n",
    "# print(f'x_4 shape: {x_4.shape}')\n",
    "# LSTM(128, return_sequences=True, dropout=0.2)(x_4)\n",
    "\n",
    "# # model.add(Flatten())\n",
    "# # RNN layers for capturing temporal dependencies\n",
    "# # [[x], [x], [x], ...]\n",
    "# # [x, x, x, x, x]\n",
    "# # (1, 1700)\n",
    "\n",
    "# # (1700)\n",
    "# # model.add(Reshape((1700)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # CNN layers for feature extraction\n",
    "# model.add(Conv2D(10, kernel_size=(3,3), activation='relu', input_shape=(5, 513, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "# # model.add(Reshape(target_shape=(1, 1700)))\n",
    "# model.add(Flatten())\n",
    "# # RNN layers for capturing temporal dependencies\n",
    "# # [[x], [x], [x], ...]\n",
    "# # [x, x, x, x, x]\n",
    "# # (1, 1700)\n",
    "\n",
    "# # (1700)\n",
    "# # model.add(LSTM(128, return_sequences=True, dropout=0.2))\n",
    "# # model.add(GRU(128, return_sequences=True, dropout=0.2))\n",
    "# model.add(Dense(88, activation='relu'))\n",
    "# # Output layer for pitch detection (binary classification for each note)\n",
    "# model.add(Dense(88, activation='sigmoid'))\n",
    "# # Compile model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# #ValueError: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 5, 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_input_data=[]\n",
    "# input_length=input.shape[0]\n",
    "# for i in range(input_length-4): \n",
    "#     training_input_data.append(np.expand_dims(input.iloc[i: i+5, :].values, axis=2))\n",
    "\n",
    "# training_input_data=np.array(training_input_data)\n",
    "# training_input_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_labels_data=[]\n",
    "# labels_length=labels.shape[0]\n",
    "# for i in range(labels_length-4): \n",
    "#     training_labels_data.append(labels.iloc[i: i+5, :].max().values)\n",
    "\n",
    "# training_labels_data=np.array(training_labels_data)\n",
    "# training_labels_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(training_input_data, training_labels_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, inputs_df, labels_df):\n",
    "        self.inputs = torch.FloatTensor(inputs_df.values)\n",
    "        self.labels = torch.FloatTensor(labels_df.values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx].view(1, 1, 513), self.labels[idx]  # [channels, time, freq]\n",
    "\n",
    "class PitchDetectionModel(nn.Module):\n",
    "    def __init__(self, num_pitches=88):\n",
    "        super(PitchDetectionModel, self).__init__()\n",
    "        \n",
    "        # Reduced number of pooling layers and smaller kernels\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(1, 32, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1, 2)),  # Only pool frequency dimension\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            \n",
    "            # Third conv block without pooling\n",
    "            nn.Conv2d(64, 128, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten all dimensions except batch\n",
    "            nn.Linear(128 * 128, 256),  # Adjust these numbers based on your input size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_pitches),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, channels, time, freq]\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def prepare_training(inputs_df, labels_df, batch_size=32, test_size=0.2, random_state=42):\n",
    "    inputs_train, inputs_val, labels_train, labels_val = train_test_split(\n",
    "        inputs_df, labels_df, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_dataset = SpectrogramDataset(inputs_train, labels_train)\n",
    "    val_dataset = SpectrogramDataset(inputs_val, labels_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def main(inputs_df, labels_df):\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Input DataFrame shape: {inputs_df.shape}\")\n",
    "    print(f\"Labels DataFrame shape: {labels_df.shape}\")\n",
    "    \n",
    "    # Initialize model and move to device\n",
    "    model = PitchDetectionModel(num_pitches=labels_df.shape[1])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = prepare_training(inputs_df, labels_df, batch_size=32)\n",
    "    \n",
    "    # Initialize loss and optimizer\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 50\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_pitch_model.pth')\n",
    "            print(\"Saved best model!\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    main(inputs, labels)\n",
    "\n",
    "main(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Connor\\AppData\\Local\\Temp\\ipykernel_21448\\3797667306.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n",
      "c:\\Users\\Connor\\anaconda3\\envs\\REALDEV\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Connor\\anaconda3\\envs\\REALDEV\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Connor\\anaconda3\\envs\\REALDEV\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall Model Performance ===\n",
      "Overall Accuracy: 0.9939\n",
      "Overall Precision: 0.9104\n",
      "Overall Recall: 0.7996\n",
      "Overall F1: 0.8514\n",
      "\n",
      "=== Top 5 Best Performing Pitches ===\n",
      "       Pitch  Precision    Recall  F1 Score  Accuracy\n",
      "54  Pitch_54   0.949062  0.895447  0.921475  0.997833\n",
      "44  Pitch_44   0.944853  0.877133  0.909735  0.999389\n",
      "45  Pitch_45   0.902410  0.915325  0.908822  0.988936\n",
      "49  Pitch_49   0.993056  0.826590  0.902208  0.999629\n",
      "62  Pitch_62   0.934385  0.871176  0.901674  0.996132\n",
      "\n",
      "=== Top 5 Worst Performing Pitches ===\n",
      "     Pitch  Precision  Recall  F1 Score  Accuracy\n",
      "0  Pitch_0        0.0     0.0       0.0       1.0\n",
      "1  Pitch_1        0.0     0.0       0.0       1.0\n",
      "2  Pitch_2        0.0     0.0       0.0       1.0\n",
      "3  Pitch_3        0.0     0.0       0.0       1.0\n",
      "4  Pitch_4        0.0     0.0       0.0       1.0\n",
      "\n",
      "=== Performance Distribution ===\n",
      "\n",
      "F1 Score Distribution:\n",
      "count    88.000000\n",
      "mean      0.410697\n",
      "std       0.424935\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.856470\n",
      "max       0.921475\n",
      "Name: F1 Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(model, data_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Convert predictions to binary using threshold\n",
    "            predictions = (outputs > threshold).float()\n",
    "            \n",
    "            # Move to CPU and convert to numpy for sklearn metrics\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            \n",
    "            all_predictions.append(predictions)\n",
    "            all_targets.append(target)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # Per-pitch metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average=None)\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(\n",
    "        all_targets.flatten(), \n",
    "        all_predictions.flatten(), \n",
    "        average='binary'\n",
    "    )\n",
    "    \n",
    "    # Calculate accuracy per pitch\n",
    "    pitch_accuracy = (all_targets == all_predictions).mean(axis=0)\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(all_targets.flatten(), all_predictions.flatten())\n",
    "    \n",
    "    # Create a DataFrame with all metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Pitch': [f'Pitch_{i}' for i in range(len(precision))],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': pitch_accuracy\n",
    "    })\n",
    "    \n",
    "    # Add overall metrics\n",
    "    overall_metrics = {\n",
    "        'Overall Accuracy': overall_accuracy,\n",
    "        'Overall Precision': overall_precision,\n",
    "        'Overall Recall': overall_recall,\n",
    "        'Overall F1': overall_f1\n",
    "    }\n",
    "    \n",
    "    return metrics_df, overall_metrics\n",
    "\n",
    "def print_evaluation_results(metrics_df, overall_metrics):\n",
    "    print(\"\\n=== Overall Model Performance ===\")\n",
    "    for metric, value in overall_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Top 5 Best Performing Pitches ===\")\n",
    "    print(metrics_df.nlargest(5, 'F1 Score')[['Pitch', 'Precision', 'Recall', 'F1 Score', 'Accuracy']])\n",
    "    \n",
    "    print(\"\\n=== Top 5 Worst Performing Pitches ===\")\n",
    "    print(metrics_df.nsmallest(5, 'F1 Score')[['Pitch', 'Precision', 'Recall', 'F1 Score', 'Accuracy']])\n",
    "    \n",
    "    # Calculate performance distribution\n",
    "    print(\"\\n=== Performance Distribution ===\")\n",
    "    print(\"\\nF1 Score Distribution:\")\n",
    "    print(metrics_df['F1 Score'].describe())\n",
    "\n",
    "# Usage example:\n",
    "def evaluate_saved_model(model_path, inputs_df, labels_df, batch_size=32):\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize model\n",
    "    model = PitchDetectionModel(num_pitches=labels_df.shape[1])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = SpectrogramDataset(inputs_df, labels_df)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics_df, overall_metrics = evaluate_model(model, data_loader, device)\n",
    "    \n",
    "    # Print results\n",
    "    print_evaluation_results(metrics_df, overall_metrics)\n",
    "    \n",
    "    return metrics_df, overall_metrics\n",
    "\n",
    "# To use this with your saved model:\n",
    "\"\"\"\n",
    "metrics_df, overall_metrics = evaluate_saved_model(\n",
    "    model_path='best_pitch_model.pth',\n",
    "    inputs_df=inputs,\n",
    "    labels_df=labels\n",
    ")\n",
    "\n",
    "# To save the metrics to CSV:\n",
    "metrics_df.to_csv('pitch_detection_metrics.csv', index=False)\n",
    "\"\"\"\n",
    "\n",
    "metrics_df, overall_metrics = evaluate_saved_model(\n",
    "    model_path='best_pitch_model.pth',\n",
    "    inputs_df=inputs,\n",
    "    labels_df=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Initialize\\nmodel = PitchDetectionModel(num_pitches=88)\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\\nbest_loss = float('inf')\\n\\n# Training loop\\nfor epoch in range(num_epochs):\\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\\n    val_loss = validate(model, val_loader, criterion, device)\\n    \\n    if val_loss < best_loss:\\n        best_loss = val_loss\\n        # Save best state\\n        save_best_state(model)\\n        \\n        # Optional: save comprehensive state\\n        save_training_state(model, optimizer, epoch, best_loss)\\n\\n# Save full model at the end if desired\\nsave_full_model(model)\\n\""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Option 1: Save just the best state dict (most common approach)\n",
    "def save_best_state(model, filepath='best_model_state.pth'):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    \n",
    "# Option 2: Save the entire model\n",
    "def save_full_model(model, filepath='full_model.pkl'):\n",
    "    torch.save(model, filepath)\n",
    "    \n",
    "# Option 3: Save comprehensive training state\n",
    "def save_training_state(model, optimizer, epoch, best_loss, filepath='training_state.pth'):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "    }\n",
    "    torch.save(state, filepath)\n",
    "\n",
    "# Loading functions for each approach\n",
    "def load_best_state(model, filepath='best_model_state.pth'):\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    return model\n",
    "\n",
    "def load_full_model(filepath='full_model.pkl'):\n",
    "    return torch.load(filepath)\n",
    "\n",
    "def load_training_state(model, optimizer, filepath='training_state.pth'):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    return model, optimizer, epoch, best_loss\n",
    "\n",
    "# Example usage during training:\n",
    "\"\"\"\n",
    "# Initialize\n",
    "model = PitchDetectionModel(num_pitches=88)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        # Save best state\n",
    "        save_best_state(model)\n",
    "        \n",
    "        # Optional: save comprehensive state\n",
    "        save_training_state(model, optimizer, epoch, best_loss)\n",
    "\n",
    "# Save full model at the end if desired\n",
    "save_full_model(model)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REALDEV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
