{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import librosa\n",
    "import numpy as np\n",
    "from audio_midi_pipeline import process_files\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, GRU, Dense, Flatten, Reshape\n",
    "\n",
    "# Additional import for setting up the input shape\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_files('songs/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_06_Track06_wav.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[:, 513:]\n",
    "inputs = df.iloc[:, :513]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, inputs_df, labels_df):\n",
    "        self.inputs = torch.FloatTensor(inputs_df.values)\n",
    "        self.labels = torch.FloatTensor(labels_df.values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx].view(1, 1, 513), self.labels[idx]  # [channels, time, freq]\n",
    "\n",
    "class PitchDetectionModel(nn.Module):\n",
    "    def __init__(self, num_pitches=88):\n",
    "        super(PitchDetectionModel, self).__init__()\n",
    "        \n",
    "        # Reduced number of pooling layers and smaller kernels\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(1, 32, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1, 2)),  # Only pool frequency dimension\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            \n",
    "            # Third conv block without pooling\n",
    "            nn.Conv2d(64, 128, kernel_size=(1, 3), padding=(0, 1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  # Flatten all dimensions except batch\n",
    "            nn.Linear(128 * 128, 256),  # Adjust these numbers based on your input size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_pitches),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, channels, time, freq]\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def prepare_training(inputs_df, labels_df, batch_size=32, test_size=0.2, random_state=42):\n",
    "    inputs_train, inputs_val, labels_train, labels_val = train_test_split(\n",
    "        inputs_df, labels_df, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_dataset = SpectrogramDataset(inputs_train, labels_train)\n",
    "    val_dataset = SpectrogramDataset(inputs_val, labels_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def main(inputs_df, labels_df):\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Input DataFrame shape: {inputs_df.shape}\")\n",
    "    print(f\"Labels DataFrame shape: {labels_df.shape}\")\n",
    "    \n",
    "    # Initialize model and move to device\n",
    "    model = PitchDetectionModel(num_pitches=labels_df.shape[1])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader = prepare_training(inputs_df, labels_df, batch_size=32)\n",
    "    \n",
    "    # Initialize loss and optimizer\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 30\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model, 'full_model.pth')\n",
    "            print(\"Saved best model!\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    main(inputs, labels)\n",
    "\n",
    "main(inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(model, data_loader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Convert predictions to binary using threshold\n",
    "            predictions = (outputs > threshold).float()\n",
    "            \n",
    "            # Move to CPU and convert to numpy for sklearn metrics\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            \n",
    "            all_predictions.append(predictions)\n",
    "            all_targets.append(target)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    # Per-pitch metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average=None)\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(\n",
    "        all_targets.flatten(), \n",
    "        all_predictions.flatten(), \n",
    "        average='binary'\n",
    "    )\n",
    "    \n",
    "    # Calculate accuracy per pitch\n",
    "    pitch_accuracy = (all_targets == all_predictions).mean(axis=0)\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(all_targets.flatten(), all_predictions.flatten())\n",
    "    \n",
    "    # Create a DataFrame with all metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Pitch': [f'Pitch_{i}' for i in range(len(precision))],\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': pitch_accuracy\n",
    "    })\n",
    "    \n",
    "    # Add overall metrics\n",
    "    overall_metrics = {\n",
    "        'Overall Accuracy': overall_accuracy,\n",
    "        'Overall Precision': overall_precision,\n",
    "        'Overall Recall': overall_recall,\n",
    "        'Overall F1': overall_f1\n",
    "    }\n",
    "    \n",
    "    return metrics_df, overall_metrics\n",
    "\n",
    "def print_evaluation_results(metrics_df, overall_metrics):\n",
    "    print(\"\\n=== Overall Model Performance ===\")\n",
    "    for metric, value in overall_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Top 5 Best Performing Pitches ===\")\n",
    "    print(metrics_df.nlargest(5, 'F1 Score')[['Pitch', 'Precision', 'Recall', 'F1 Score', 'Accuracy']])\n",
    "    \n",
    "    print(\"\\n=== Top 5 Worst Performing Pitches ===\")\n",
    "    print(metrics_df.nsmallest(5, 'F1 Score')[['Pitch', 'Precision', 'Recall', 'F1 Score', 'Accuracy']])\n",
    "    \n",
    "    # Calculate performance distribution\n",
    "    print(\"\\n=== Performance Distribution ===\")\n",
    "    print(\"\\nF1 Score Distribution:\")\n",
    "    print(metrics_df['F1 Score'].describe())\n",
    "\n",
    "# Usage example:\n",
    "def evaluate_saved_model(model_path, inputs_df, labels_df, batch_size=32):\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize model\n",
    "    model = PitchDetectionModel(num_pitches=labels_df.shape[1])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = SpectrogramDataset(inputs_df, labels_df)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics_df, overall_metrics = evaluate_model(model, data_loader, device)\n",
    "    \n",
    "    # Print results\n",
    "    print_evaluation_results(metrics_df, overall_metrics)\n",
    "    \n",
    "    return metrics_df, overall_metrics\n",
    "\n",
    "# To use this with your saved model:\n",
    "\"\"\"\n",
    "metrics_df, overall_metrics = evaluate_saved_model(\n",
    "    model_path='best_pitch_model.pth',\n",
    "    inputs_df=inputs,\n",
    "    labels_df=labels\n",
    ")\n",
    "\n",
    "# To save the metrics to CSV:\n",
    "metrics_df.to_csv('pitch_detection_metrics.csv', index=False)\n",
    "\"\"\"\n",
    "\n",
    "metrics_df, overall_metrics = evaluate_saved_model(\n",
    "    model_path='best_pitch_model.pth',\n",
    "    inputs_df=inputs,\n",
    "    labels_df=labels\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REALDEV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
